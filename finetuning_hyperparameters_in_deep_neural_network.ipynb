{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from random import seed\n",
    "seed(1)\n",
    "seed = 43\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Keras Version: \",keras.__version__)\n",
    "\n",
    "\n",
    "kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "# change your local path here\n",
    "if kaggle == 1 :\n",
    "    MNIST_PATH= '../input/digit-recognizer'\n",
    "else:\n",
    "    MNIST_PATH= '../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer'\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(MNIST_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow Version:  2.3.0\n",
      "Keras Version:  2.4.0\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\keras_reg_160_10_002.sav\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\keras_reg_jl_160_10_002.sav\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\sample_submission.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\test.csv\n",
      "../Digit_Recognition_with_a_Deep_Neural_Network/data/input/digit-recognizer\\train.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction - MNIST Training Competition\n",
    "This notebook is a fork of my previous developed notebook for digit recognition. Therefore you will find some parts that look common the the notebook <a href=\"https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\">Digit Recognition with a Deep Neural Network</a> and some parts that are completely different.\n",
    "\n",
    "With this I want to take a deeper look in some parts of finetuning hyperparameters. The following list shows some of the finetuning parameters which I will take a look into, one or two ore more ... :\n",
    "- Dwindling / Exploding Gradients\n",
    "    - <b>Initializing the Weights</b>\n",
    "    - <b>Batchnormalization</b>\n",
    "    - <s>Gradient Clipping</s>\n",
    "    - <b>Saturated Activataion Functions</b>\n",
    "- Optimizers\n",
    "    - <s>Momentum Optimizers</s>\n",
    "    - <s>Nesterov</s>\n",
    "    - <s>AdaGrad</s>\n",
    "    - <s>RMSProp</s>\n",
    "    - <b>Adam - Optimizer</b>\n",
    "    - <s>Scheduling Learnrate</s>\n",
    "- Regulations\n",
    "    - <s>Drop-Outs</s>\n",
    "    - <b>l1 / l2 - Regulations</b>\n",
    "    - <s>Monte-Carlo Drop-out ???</s>\n",
    "    - <s>Max Norm Regulations ????</s>\n",
    "\n",
    "Not part of this notebook will be the use of pretrained neural networks (Transferlearning). I just want to list this here for the sake of completeness.\n",
    "\n",
    "Link to the data topic: https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "As in the previous notebooks I will use Tensorflow with Keras. I already mentioned in other notebooks, I will skip some explanations about the data set here. Moreover I will use the already discovered knowledge about the data and transform/prepare the data rightaway.\n",
    "\n",
    "## Notebook Versions with Different Hyperparameter Configurations\n",
    "As described in the part above, I used/tested different hyperparameter settings to get a little bit closer to its effects on the neural network and the network's results. I know that there are parameters that effect other parameters when they have changed (and therefore should have been changed as well), however in these cases I just tried a little bit around. Sometimes I kept one or two parameters together, which should be together (e.g. kernel initializer \"lecun\" and activation function \"selu\") and sometimes not. The main purpose here was to use them and see the results.\n",
    "\n",
    "Therefore on Kaggle you can look in the different versions of this notebook if you are interested. In the following I will list some versions with the used hyperparameter config in it:\n",
    "- Version 7 and 6:\n",
    "    - Activation Function - \"relu\"\n",
    "    - Initializing Weights - \"He Normalization\"\n",
    "    - Batchnormalization\n",
    "- Version 9:\n",
    "    - Activation Function - \"selu\"\n",
    "    - Initializing Weights - \"LeCun Normal\"\n",
    "- Version 12 and 14:\n",
    "    - Regularisation with L1 and L2\n",
    "- Version 15:\n",
    "    - Activation Function - \"relu\"\n",
    "    - Initializing Weights - \"He Normalization\"\n",
    "    - Batchnormalization\n",
    "    - Optimizer - \"Adam\"\n",
    "\n",
    "The current best run was based on the Version 7 with an accuracy of 0.97657 on the kaggle competition \"Digit Recognzier\"\n",
    "\n",
    "\n",
    "## My other Projects\n",
    "If you are interested in some more clearly analysis of the dataset take a look into my other notebooks about the MNIS-dataset:\n",
    "- Digit Recognition with a Deep Neural Network: https://www.kaggle.com/skiplik/digit-recognition-with-a-deep-neural-network\n",
    "- Another MNIST Try: https://www.kaggle.com/skiplik/another-mnist-try\n",
    "- First NN by Detecting Handwritten Characters: https://www.kaggle.com/skiplik/first-nn-by-detecting-handwritten-characters\n",
    "...\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "\n",
    "def load_mnist_data(minist_path, csv_file):\n",
    "    csv_path = os.path.join(minist_path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_mnist_data_manuel(minist_path, csv_file):\n",
    "    csv_path = os.path.join(minist_path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "\n",
    "def split_train_val(data, val_ratio):\n",
    "    return \n",
    "    \n",
    "\n",
    "train = load_mnist_data(MNIST_PATH,CSV_FILE_TRAIN)\n",
    "test = load_mnist_data(MNIST_PATH,CSV_FILE_TEST)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "y = train['label'].copy()\n",
    "X = train.drop(['label'], axis=1)\n",
    "\n",
    "X_test = test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train / Val Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "print(\"Shape of the Features: \",X.shape)\n",
    "print(\"Shape of the Labels: \", y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the Features:  (42000, 784)\n",
      "Shape of the Labels:  (42000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Value Count\r\n",
    "Visualizing the label distribution of the full train dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "train.value_counts('label')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=0.20\n",
    "                                                  , stratify=y\n",
    "                                                 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing the equally splitted train- and val-sets based on the given label y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "print(\"Train - Set Distribution\")\n",
    "print(y_train.value_counts() / y_train.value_counts().sum() )\n",
    "print('--------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------')\n",
    "print(\"Val - Set Distribution\")\n",
    "print(y_val.value_counts() / y_val.value_counts().sum() )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train - Set Distribution\n",
      "1    0.111518\n",
      "7    0.104792\n",
      "3    0.103601\n",
      "9    0.099702\n",
      "2    0.099464\n",
      "6    0.098512\n",
      "0    0.098363\n",
      "4    0.096964\n",
      "8    0.096726\n",
      "5    0.090357\n",
      "Name: label, dtype: float64\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Val - Set Distribution\n",
      "1    0.111548\n",
      "7    0.104762\n",
      "3    0.103571\n",
      "9    0.099762\n",
      "2    0.099405\n",
      "0    0.098452\n",
      "6    0.098452\n",
      "4    0.096905\n",
      "8    0.096786\n",
      "5    0.090357\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "print(\"X: \", X.shape)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_val: \", X_val.shape)\n",
    "\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_val: \", y_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X:  (42000, 784)\n",
      "X_train:  (33600, 784)\n",
      "X_val:  (8400, 784)\n",
      "y_train:  (33600,)\n",
      "y_val:  (8400,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Transforming Piplines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    #('normalizer', Normalizer())\n",
    "    ('std_scalar',StandardScaler())\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "X_train_prep = pipeline.fit_transform(X_train)      # fitting the pipeline to the train and transform it\n",
    "X_val_prep = pipeline.transform(X_val)              # transform val data with this information"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Deep Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Model Visualization with Tensorboard (not for Kaggle)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "print(\"Relative root_logdir: \",root_logdir)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relative root_logdir:  ../../tensorboard-logs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(\"Current run logdir for Tensorboard: \", run_logdir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current run logdir for Tensorboard:  ../../tensorboard-logs\\run_2021_10_04-12_44_59\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "run_logdir"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../tensorboard-logs\\\\run_2021_10_04-12_44_59'"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keras Callbacks for Tensorboard\n",
    "With Keras there is a way of using Callbacks for the Tensorboard to write log files for the board and visualize the different graphs (loss and val curve)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "input_shape=[784]\n",
    "input_shape_notFlattened=[28,28]\n",
    "\n",
    "\n",
    "learning_rt = 1e-03 \n",
    "activation_fn = \"relu\"\n",
    "initializer = \"he_normal\"\n",
    "regularizer =  keras.regularizers.l2(0.01)\n",
    "\n",
    "# Model building\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Flatten(input_shape=input_shape_notFlattened))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(500, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer)) ## add  kernel_regularizer=keras.regularizers.l2(0.01)) ???\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rt)\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 916,946\n",
      "Trainable params: 911,978\n",
      "Non-trainable params: 4,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Checkpoints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_train_model.h5\", save_best_only=True, save_weights_only=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "history = model.fit(X_train_prep, y_train, epochs=200, validation_data=(X_val_prep, y_val), callbacks=[checkpoint_cb, keras.callbacks.EarlyStopping(patience=20), tensorboard_cb])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/1050 [..............................] - ETA: 8:18 - loss: 42.8592 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.9445s). Check your callbacks.\n",
      "1044/1050 [============================>.] - ETA: 0s - loss: 8.3635 - accuracy: 0.8495WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "1050/1050 [==============================] - 8s 8ms/step - loss: 8.3228 - accuracy: 0.8493 - val_loss: 1.0792 - val_accuracy: 0.8963\n",
      "Epoch 2/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.1528 - accuracy: 0.8535 - val_loss: 1.0300 - val_accuracy: 0.8927\n",
      "Epoch 3/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.1355 - accuracy: 0.8576 - val_loss: 1.1067 - val_accuracy: 0.8755\n",
      "Epoch 4/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.1671 - accuracy: 0.8620 - val_loss: 1.0840 - val_accuracy: 0.8904\n",
      "Epoch 5/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.1335 - accuracy: 0.8714 - val_loss: 0.9490 - val_accuracy: 0.9218\n",
      "Epoch 6/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.0959 - accuracy: 0.8758 - val_loss: 0.9718 - val_accuracy: 0.9135\n",
      "Epoch 7/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.0045 - accuracy: 0.8891 - val_loss: 0.9143 - val_accuracy: 0.9262\n",
      "Epoch 8/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.9391 - accuracy: 0.8951 - val_loss: 0.8740 - val_accuracy: 0.9060\n",
      "Epoch 9/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.8409 - accuracy: 0.9024 - val_loss: 0.6922 - val_accuracy: 0.9399\n",
      "Epoch 10/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.7514 - accuracy: 0.9090 - val_loss: 0.6849 - val_accuracy: 0.9265\n",
      "Epoch 11/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.6899 - accuracy: 0.9132 - val_loss: 0.5762 - val_accuracy: 0.9395\n",
      "Epoch 12/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.6471 - accuracy: 0.9174 - val_loss: 0.6079 - val_accuracy: 0.9293\n",
      "Epoch 13/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.6035 - accuracy: 0.9205 - val_loss: 0.5401 - val_accuracy: 0.9368\n",
      "Epoch 14/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.5718 - accuracy: 0.9226 - val_loss: 0.4987 - val_accuracy: 0.9464\n",
      "Epoch 15/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.5419 - accuracy: 0.9262 - val_loss: 0.4777 - val_accuracy: 0.9456\n",
      "Epoch 16/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.5205 - accuracy: 0.9260 - val_loss: 0.4397 - val_accuracy: 0.9502\n",
      "Epoch 17/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.5129 - accuracy: 0.9253 - val_loss: 0.4494 - val_accuracy: 0.9436\n",
      "Epoch 18/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4840 - accuracy: 0.9296 - val_loss: 0.3965 - val_accuracy: 0.9548\n",
      "Epoch 19/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.4712 - accuracy: 0.9301 - val_loss: 0.4341 - val_accuracy: 0.9458\n",
      "Epoch 20/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4576 - accuracy: 0.9324 - val_loss: 0.4151 - val_accuracy: 0.9462\n",
      "Epoch 21/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4474 - accuracy: 0.9322 - val_loss: 0.4567 - val_accuracy: 0.9349\n",
      "Epoch 22/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.4459 - accuracy: 0.9314 - val_loss: 0.3722 - val_accuracy: 0.9539\n",
      "Epoch 23/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4275 - accuracy: 0.9341 - val_loss: 0.3780 - val_accuracy: 0.9523\n",
      "Epoch 24/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4165 - accuracy: 0.9350 - val_loss: 0.3685 - val_accuracy: 0.9519\n",
      "Epoch 25/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4092 - accuracy: 0.9366 - val_loss: 0.3652 - val_accuracy: 0.9539\n",
      "Epoch 26/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4074 - accuracy: 0.9367 - val_loss: 0.3909 - val_accuracy: 0.9477\n",
      "Epoch 27/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.4081 - accuracy: 0.9347 - val_loss: 0.3625 - val_accuracy: 0.9517\n",
      "Epoch 28/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3973 - accuracy: 0.9359 - val_loss: 0.3556 - val_accuracy: 0.9538\n",
      "Epoch 29/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3861 - accuracy: 0.9397 - val_loss: 0.3677 - val_accuracy: 0.9479\n",
      "Epoch 30/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3805 - accuracy: 0.9394 - val_loss: 0.3508 - val_accuracy: 0.9505\n",
      "Epoch 31/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3788 - accuracy: 0.9377 - val_loss: 0.3335 - val_accuracy: 0.9539\n",
      "Epoch 32/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3874 - accuracy: 0.9361 - val_loss: 0.3461 - val_accuracy: 0.9552\n",
      "Epoch 33/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3681 - accuracy: 0.9401 - val_loss: 0.3523 - val_accuracy: 0.9481\n",
      "Epoch 34/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3686 - accuracy: 0.9390 - val_loss: 0.3349 - val_accuracy: 0.9532\n",
      "Epoch 35/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3573 - accuracy: 0.9426 - val_loss: 0.3416 - val_accuracy: 0.9538\n",
      "Epoch 36/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3624 - accuracy: 0.9403 - val_loss: 0.3557 - val_accuracy: 0.9460\n",
      "Epoch 37/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3536 - accuracy: 0.9424 - val_loss: 0.3378 - val_accuracy: 0.9549\n",
      "Epoch 38/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3539 - accuracy: 0.9413 - val_loss: 0.3240 - val_accuracy: 0.9546\n",
      "Epoch 39/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3538 - accuracy: 0.9404 - val_loss: 0.3402 - val_accuracy: 0.9485\n",
      "Epoch 40/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3515 - accuracy: 0.9416 - val_loss: 0.3258 - val_accuracy: 0.9519\n",
      "Epoch 41/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3481 - accuracy: 0.9414 - val_loss: 0.3101 - val_accuracy: 0.9548\n",
      "Epoch 42/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3402 - accuracy: 0.9420 - val_loss: 0.3321 - val_accuracy: 0.9563\n",
      "Epoch 43/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3468 - accuracy: 0.9411 - val_loss: 0.3426 - val_accuracy: 0.9489\n",
      "Epoch 44/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3398 - accuracy: 0.9434 - val_loss: 0.3077 - val_accuracy: 0.9574\n",
      "Epoch 45/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3417 - accuracy: 0.9417 - val_loss: 0.3009 - val_accuracy: 0.9570\n",
      "Epoch 46/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3393 - accuracy: 0.9417 - val_loss: 0.3187 - val_accuracy: 0.9542\n",
      "Epoch 47/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3332 - accuracy: 0.9431 - val_loss: 0.3242 - val_accuracy: 0.9533\n",
      "Epoch 48/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3401 - accuracy: 0.9419 - val_loss: 0.3011 - val_accuracy: 0.9557\n",
      "Epoch 49/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3307 - accuracy: 0.9450 - val_loss: 0.3197 - val_accuracy: 0.9545\n",
      "Epoch 50/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3259 - accuracy: 0.9442 - val_loss: 0.3187 - val_accuracy: 0.9549\n",
      "Epoch 51/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3321 - accuracy: 0.9432 - val_loss: 0.3129 - val_accuracy: 0.9539\n",
      "Epoch 52/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3208 - accuracy: 0.9443 - val_loss: 0.3176 - val_accuracy: 0.9514\n",
      "Epoch 53/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3307 - accuracy: 0.9425 - val_loss: 0.3182 - val_accuracy: 0.9546\n",
      "Epoch 54/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3222 - accuracy: 0.9446 - val_loss: 0.3048 - val_accuracy: 0.9536\n",
      "Epoch 55/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3250 - accuracy: 0.9424 - val_loss: 0.3091 - val_accuracy: 0.9575\n",
      "Epoch 56/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3206 - accuracy: 0.9439 - val_loss: 0.3264 - val_accuracy: 0.9442\n",
      "Epoch 57/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3192 - accuracy: 0.9424 - val_loss: 0.3030 - val_accuracy: 0.9617\n",
      "Epoch 58/200\n",
      "1050/1050 [==============================] - 8s 8ms/step - loss: 0.3149 - accuracy: 0.9456 - val_loss: 0.3118 - val_accuracy: 0.9526\n",
      "Epoch 59/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3194 - accuracy: 0.9442 - val_loss: 0.2977 - val_accuracy: 0.9557\n",
      "Epoch 60/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3206 - accuracy: 0.9436 - val_loss: 0.3129 - val_accuracy: 0.9505\n",
      "Epoch 61/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3120 - accuracy: 0.9441 - val_loss: 0.3154 - val_accuracy: 0.9546\n",
      "Epoch 62/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3125 - accuracy: 0.9460 - val_loss: 0.2923 - val_accuracy: 0.9573\n",
      "Epoch 63/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3148 - accuracy: 0.9444 - val_loss: 0.3138 - val_accuracy: 0.9519\n",
      "Epoch 64/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3059 - accuracy: 0.9472 - val_loss: 0.2985 - val_accuracy: 0.9571\n",
      "Epoch 65/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3068 - accuracy: 0.9472 - val_loss: 0.2932 - val_accuracy: 0.9550\n",
      "Epoch 66/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3103 - accuracy: 0.9441 - val_loss: 0.3283 - val_accuracy: 0.9471\n",
      "Epoch 67/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3083 - accuracy: 0.9449 - val_loss: 0.2958 - val_accuracy: 0.9556\n",
      "Epoch 68/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3040 - accuracy: 0.9464 - val_loss: 0.2927 - val_accuracy: 0.9565\n",
      "Epoch 69/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3060 - accuracy: 0.9455 - val_loss: 0.2974 - val_accuracy: 0.9513\n",
      "Epoch 70/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3091 - accuracy: 0.9441 - val_loss: 0.3093 - val_accuracy: 0.9548\n",
      "Epoch 71/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3021 - accuracy: 0.9475 - val_loss: 0.3104 - val_accuracy: 0.9471\n",
      "Epoch 72/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3033 - accuracy: 0.9455 - val_loss: 0.3059 - val_accuracy: 0.9508\n",
      "Epoch 73/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3054 - accuracy: 0.9448 - val_loss: 0.3094 - val_accuracy: 0.9510\n",
      "Epoch 74/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3015 - accuracy: 0.9471 - val_loss: 0.3219 - val_accuracy: 0.9532\n",
      "Epoch 75/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3054 - accuracy: 0.9457 - val_loss: 0.3477 - val_accuracy: 0.9554\n",
      "Epoch 76/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3018 - accuracy: 0.9460 - val_loss: 0.2892 - val_accuracy: 0.9551\n",
      "Epoch 77/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2973 - accuracy: 0.9484 - val_loss: 0.2986 - val_accuracy: 0.9564\n",
      "Epoch 78/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3000 - accuracy: 0.9466 - val_loss: 0.2750 - val_accuracy: 0.9590\n",
      "Epoch 79/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2968 - accuracy: 0.9472 - val_loss: 0.3112 - val_accuracy: 0.9532\n",
      "Epoch 80/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.3002 - accuracy: 0.9449 - val_loss: 0.3124 - val_accuracy: 0.9513\n",
      "Epoch 81/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2974 - accuracy: 0.9476 - val_loss: 0.2873 - val_accuracy: 0.9568\n",
      "Epoch 82/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2968 - accuracy: 0.9469 - val_loss: 0.2869 - val_accuracy: 0.9604\n",
      "Epoch 83/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2943 - accuracy: 0.9474 - val_loss: 0.2811 - val_accuracy: 0.9586\n",
      "Epoch 84/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2965 - accuracy: 0.9459 - val_loss: 0.2987 - val_accuracy: 0.9542\n",
      "Epoch 85/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2963 - accuracy: 0.9471 - val_loss: 0.2849 - val_accuracy: 0.9546\n",
      "Epoch 86/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2911 - accuracy: 0.9483 - val_loss: 0.2868 - val_accuracy: 0.9551\n",
      "Epoch 87/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2950 - accuracy: 0.9475 - val_loss: 0.3009 - val_accuracy: 0.9536\n",
      "Epoch 88/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2916 - accuracy: 0.9470 - val_loss: 0.2839 - val_accuracy: 0.9586\n",
      "Epoch 89/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2948 - accuracy: 0.9463 - val_loss: 0.3156 - val_accuracy: 0.9514\n",
      "Epoch 90/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2919 - accuracy: 0.9460 - val_loss: 0.3279 - val_accuracy: 0.9565\n",
      "Epoch 91/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2884 - accuracy: 0.9485 - val_loss: 0.3054 - val_accuracy: 0.9524\n",
      "Epoch 92/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2890 - accuracy: 0.9493 - val_loss: 0.3036 - val_accuracy: 0.9574\n",
      "Epoch 93/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2858 - accuracy: 0.9493 - val_loss: 0.2997 - val_accuracy: 0.9563\n",
      "Epoch 94/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2923 - accuracy: 0.9474 - val_loss: 0.2886 - val_accuracy: 0.9593\n",
      "Epoch 95/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2930 - accuracy: 0.9454 - val_loss: 0.2913 - val_accuracy: 0.9571\n",
      "Epoch 96/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2914 - accuracy: 0.9456 - val_loss: 0.2842 - val_accuracy: 0.9564\n",
      "Epoch 97/200\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.2867 - accuracy: 0.9483 - val_loss: 0.3117 - val_accuracy: 0.9593\n",
      "Epoch 98/200\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2866 - accuracy: 0.9484 - val_loss: 0.2860 - val_accuracy: 0.9537\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing the Progress"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training with Full Dataset \n",
    "In this part I will train the model with the full dataset. This time I will use the discovered hyperparameters from previous section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "\n",
    "# Model building\n",
    "model_full = keras.models.Sequential()\n",
    "\n",
    "model_full.add(keras.layers.Flatten(input_shape=input_shape_notFlattened))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(500, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer)) ## add  kernel_regularizer=keras.regularizers.l2(0.01)) ???\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "model_full.add(keras.layers.BatchNormalization())\n",
    "model_full.add(keras.layers.Dense(300, activation=activation_fn, kernel_initializer=initializer, kernel_regularizer= regularizer))\n",
    "\n",
    "model_full.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rt)\n",
    "\n",
    "\n",
    "model_full.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "model_full.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 916,946\n",
      "Trainable params: 911,978\n",
      "Non-trainable params: 4,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# creating a new log dir for tensorboard\n",
    "tensorboard_cb_f = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "checkpoint_cb_f = keras.callbacks.ModelCheckpoint(\"my_modell_full.h5\", save_best_only=False, save_weights_only=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# preparing data based on our beautifull trained data pipeline\n",
    "X_prep_all = pipeline.transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# Train the model again pleeeeease with all you got .... especially the new transformed data matrix X \n",
    "history_full = model_full.fit(X_prep_all, y, epochs=100, callbacks=[tensorboard_cb_f, checkpoint_cb_f])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "   2/1313 [..............................] - ETA: 9:39 - loss: 43.0033 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.8775s). Check your callbacks.\n",
      "1313/1313 [==============================] - 9s 7ms/step - loss: 40.0919 - accuracy: 0.6068\n",
      "Epoch 2/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 37.4432 - accuracy: 0.8290\n",
      "Epoch 3/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 35.4226 - accuracy: 0.8727\n",
      "Epoch 4/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 33.5667 - accuracy: 0.8924\n",
      "Epoch 5/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 31.8310 - accuracy: 0.9057\n",
      "Epoch 6/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 30.1897 - accuracy: 0.9142\n",
      "Epoch 7/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 28.6389 - accuracy: 0.9218\n",
      "Epoch 8/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 27.1702 - accuracy: 0.9269\n",
      "Epoch 9/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 25.7747 - accuracy: 0.9335\n",
      "Epoch 10/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 24.4575 - accuracy: 0.9374\n",
      "Epoch 11/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 23.2060 - accuracy: 0.9413\n",
      "Epoch 12/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 22.0215 - accuracy: 0.9440\n",
      "Epoch 13/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 20.8879 - accuracy: 0.9500\n",
      "Epoch 14/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 19.8256 - accuracy: 0.9514\n",
      "Epoch 15/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 18.8126 - accuracy: 0.9540\n",
      "Epoch 16/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 17.8527 - accuracy: 0.9566\n",
      "Epoch 17/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 16.9417 - accuracy: 0.9597\n",
      "Epoch 18/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 16.0755 - accuracy: 0.9621\n",
      "Epoch 19/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 15.2573 - accuracy: 0.9634\n",
      "Epoch 20/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 14.4802 - accuracy: 0.9649\n",
      "Epoch 21/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 13.7410 - accuracy: 0.9670\n",
      "Epoch 22/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 13.0400 - accuracy: 0.9691\n",
      "Epoch 23/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 12.3744 - accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 11.7440 - accuracy: 0.9731\n",
      "Epoch 25/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 11.1480 - accuracy: 0.9732\n",
      "Epoch 26/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 10.5786 - accuracy: 0.9754\n",
      "Epoch 27/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 10.0398 - accuracy: 0.9764\n",
      "Epoch 28/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 9.5304 - accuracy: 0.9760\n",
      "Epoch 29/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 9.0454 - accuracy: 0.9789\n",
      "Epoch 30/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 8.5836 - accuracy: 0.9806\n",
      "Epoch 31/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 8.1486 - accuracy: 0.9803\n",
      "Epoch 32/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 7.7342 - accuracy: 0.9817\n",
      "Epoch 33/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 7.3389 - accuracy: 0.9839\n",
      "Epoch 34/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 6.9659 - accuracy: 0.9847\n",
      "Epoch 35/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 6.6112 - accuracy: 0.9853\n",
      "Epoch 36/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 6.2764 - accuracy: 0.9864\n",
      "Epoch 37/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 5.9564 - accuracy: 0.9870\n",
      "Epoch 38/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 5.6549 - accuracy: 0.9873\n",
      "Epoch 39/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 5.3675 - accuracy: 0.9882\n",
      "Epoch 40/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 5.0944 - accuracy: 0.9901\n",
      "Epoch 41/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 4.8375 - accuracy: 0.9889\n",
      "Epoch 42/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 4.5905 - accuracy: 0.9903\n",
      "Epoch 43/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 4.3581 - accuracy: 0.9912\n",
      "Epoch 44/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 4.1366 - accuracy: 0.9921\n",
      "Epoch 45/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.9280 - accuracy: 0.9915\n",
      "Epoch 46/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.7314 - accuracy: 0.9917\n",
      "Epoch 47/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.5421 - accuracy: 0.9922\n",
      "Epoch 48/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.3631 - accuracy: 0.9926\n",
      "Epoch 49/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.1929 - accuracy: 0.9931\n",
      "Epoch 50/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 3.0311 - accuracy: 0.9935\n",
      "Epoch 51/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.8785 - accuracy: 0.9945\n",
      "Epoch 52/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.7337 - accuracy: 0.9940\n",
      "Epoch 53/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.5956 - accuracy: 0.9943\n",
      "Epoch 54/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.4638 - accuracy: 0.9950\n",
      "Epoch 55/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.3411 - accuracy: 0.9946\n",
      "Epoch 56/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.2244 - accuracy: 0.9948\n",
      "Epoch 57/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.1128 - accuracy: 0.9952\n",
      "Epoch 58/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 2.0059 - accuracy: 0.9955\n",
      "Epoch 59/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.9054 - accuracy: 0.9959\n",
      "Epoch 60/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.8106 - accuracy: 0.9958\n",
      "Epoch 61/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.7207 - accuracy: 0.9957\n",
      "Epoch 62/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.6340 - accuracy: 0.9960\n",
      "Epoch 63/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.5524 - accuracy: 0.9965\n",
      "Epoch 64/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.4747 - accuracy: 0.9967\n",
      "Epoch 65/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.4035 - accuracy: 0.9962\n",
      "Epoch 66/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.3334 - accuracy: 0.9961\n",
      "Epoch 67/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.2677 - accuracy: 0.9964\n",
      "Epoch 68/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.2054 - accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.1437 - accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.0896 - accuracy: 0.9963\n",
      "Epoch 71/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 1.0372 - accuracy: 0.9962\n",
      "Epoch 72/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.9863 - accuracy: 0.9964\n",
      "Epoch 73/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.9381 - accuracy: 0.9965\n",
      "Epoch 74/100\n",
      "1313/1313 [==============================] - 7s 6ms/step - loss: 0.8945 - accuracy: 0.9957\n",
      "Epoch 75/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.8498 - accuracy: 0.9967\n",
      "Epoch 76/100\n",
      "1313/1313 [==============================] - 7s 6ms/step - loss: 0.8096 - accuracy: 0.9965\n",
      "Epoch 77/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.7713 - accuracy: 0.9962\n",
      "Epoch 78/100\n",
      "1313/1313 [==============================] - 7s 6ms/step - loss: 0.7333 - accuracy: 0.9970\n",
      "Epoch 79/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.6981 - accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "1313/1313 [==============================] - 7s 6ms/step - loss: 0.6672 - accuracy: 0.9959\n",
      "Epoch 81/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.6354 - accuracy: 0.9965\n",
      "Epoch 82/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.6070 - accuracy: 0.9959\n",
      "Epoch 83/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.5787 - accuracy: 0.9960\n",
      "Epoch 84/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.5528 - accuracy: 0.9961\n",
      "Epoch 85/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.5294 - accuracy: 0.9950\n",
      "Epoch 86/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.5062 - accuracy: 0.9954\n",
      "Epoch 87/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.4814 - accuracy: 0.9961\n",
      "Epoch 88/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.4603 - accuracy: 0.9961\n",
      "Epoch 89/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.4405 - accuracy: 0.9956\n",
      "Epoch 90/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.4214 - accuracy: 0.9955\n",
      "Epoch 91/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.4013 - accuracy: 0.9964\n",
      "Epoch 92/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3859 - accuracy: 0.9955\n",
      "Epoch 93/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3705 - accuracy: 0.9954\n",
      "Epoch 94/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3574 - accuracy: 0.9946\n",
      "Epoch 95/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3419 - accuracy: 0.9948\n",
      "Epoch 96/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3258 - accuracy: 0.9961\n",
      "Epoch 97/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3133 - accuracy: 0.9951\n",
      "Epoch 98/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.3011 - accuracy: 0.9955\n",
      "Epoch 99/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.2915 - accuracy: 0.9948\n",
      "Epoch 100/100\n",
      "1313/1313 [==============================] - 8s 6ms/step - loss: 0.2795 - accuracy: 0.9949\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "plt.plot(pd.DataFrame(history_full.history))\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Prediction of Unknown Data (Test Data)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Peparing Test Data\r\n",
    "The test data for the competition needs to be prepared as well as did with the training data set. Therefore the trained pipeline (trained only on the training dataset) will be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "X_test_prep = pipeline.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "X_test_prep"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Competition File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['ImageId','Label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction of Testdata"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "plt.imshow(X_test_prep[43].reshape(28,28), cmap='Greys')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2be15b7ca90>"
      ]
     },
     "metadata": {},
     "execution_count": 122
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "print(\"Propability of all lables for given pixels: \", model_full.predict(X_test_prep[43].reshape(1,-1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "Propability of all lables for given pixels:  [[3.8676979e-05 2.8920460e-05 4.2562166e-05 2.6667052e-05 2.5978990e-04\n",
      "  4.2574062e-05 4.1488562e-05 6.3997300e-05 9.2300172e-05 9.9936301e-01]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "print(\"Predicted Digit: \",np.argmax(model_full.predict(X_test_prep[43].reshape(1,-1))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted Digit:  9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "predictions = model_full.predict(X_test_prep)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_6_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "i = 0\n",
    "for row in X_test_prep:\n",
    "    index = i + 1\n",
    "    predicted_label = pd.Series(np.argmax(predictions, axis=1))[i]\n",
    "\n",
    "    mnist_competition_file = mnist_competition_file.append({'ImageId': index, 'Label': predicted_label}, ignore_index = True )\n",
    "    i = i + 1\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "mnist_competition_file"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ImageId Label\n",
       "0           1     2\n",
       "1           2     0\n",
       "2           3     9\n",
       "3           4     9\n",
       "4           5     3\n",
       "...       ...   ...\n",
       "27995   27996     9\n",
       "27996   27997     7\n",
       "27997   27998     3\n",
       "27998   27999     9\n",
       "27999   28000     2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "mnist_competition_file.ImageId = mnist_competition_file.ImageId.astype(int)\n",
    "mnist_competition_file.Label = mnist_competition_file.Label.astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "mnist_competition_file.to_csv('mnist_submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b49f70aa2f17b03439dc8f4bbaf601f728142d0d0d774f4bbd10ea7a16b86ea"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('wingpuflake_keras': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}